---
title: "Eric Twitter"
output:
  html_document:
    df_print: paged
---
References:
<br>
https://stackoverflow.com/questions/26553526/how-to-add-frequency-count-labels-to-the-bars-in-a-bar-graph-using-ggplot2
<br>
https://www.statology.org/remove-axis-labels-ggplot2/
<br>

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(rtweet)
library(tidyverse)
library(tidytext)
library(textdata)
library(httpuv) # needed for twitter auth
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
# For now, use personal twitter creds
rtweet::auth_setup_default()

# first time it prompted to open another package httpuv
# and also launches a webpage to authenticate

# try a search
searchterms <- "Queen AND died"
# for n=10000 took a couple of minutes, let's time it to be sure
start1 <- Sys.time() # starting time
tw <- search_tweets(searchterms, n=10000, include_rts = F)
end1 <- Sys.time() # Finishing time
(time1 <- end1 - start1) # total time
```

```{r}
head(tw)
# head(tw$coordinates)

locs<-lat_lng(tw)
head(locs,30)
sum(!is.na(locs$lat))
# rtweet provides helpful function lag_lng()
```
```{r}
filtered_tw <- data.frame(date_time=locs$created_at, text=locs$text, lat=locs$lat, long = locs$lng)
cleaned_tw <- filtered_tw %>% mutate(date_time = as.POSIXct(date_time, format = "%a, %d %b %Y %H:%M:%s%z", tz = "PST"))

head(filtered_tw, 30)
head(cleaned_tw, 30)
```

```{r}
# make basemap
world_basemap <- ggplot() +
  borders("world", colour="gray85", fill="gray80")

# world_basemap

# only include location info
cleaned_tw_locs <- cleaned_tw %>% na.omit()
head(cleaned_tw_locs)

# plot them on the map
world_basemap +
  geom_point(data=cleaned_tw_locs, aes(x=long, y=lat), 
             col="purple", alpha=0.5) +
  labs(title = "Tweet locations for Queen and died")
```

```{r}
tw$updated_text = gsub("https.*","",tw$text)
tw$updated_text = gsub("http.*","",tw$updated_text)

#convert all texts to lowercase and remove punctuations 
rt2 <- tw %>%
  dplyr::select(updated_text) %>%
  unnest_tokens(word, updated_text)

#removing stop words
data("stop_words")
#nrow(rt2)
rt2 = anti_join(rt2,stop_words)
#nrow(rt2)
# now, I'll attach each word to its sentiment using the dictionary "bing"
rt3 = rt2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = T) %>%
  ungroup()
```

```{r}
rt3 <- rt3[!(rt3$word=="died" | rt3$word=="death" | rt3$word=="die" | rt3$word=="dead" | rt3$word=="dying" | rt3$word=="dies"),]
rt3 %>% group_by(sentiment) %>% top_n(20) %>% ungroup() %>%
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = F) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(title = "Tweets containing Queen and died", y = NULL, x = NULL) +
  geom_text(stat='identity', aes(label=n), hjust=1.25) +
  coord_flip() +
  theme_classic()
```

```{r}
(sentiCount <- rt3 %>% group_by(sentiment) %>% summarise(Count = n()))
sentiCount <- sentiCount %>% mutate(Count=Count/18.61)

# cols <- sentiCount$sentiment
# sentiCount <- as.data.frame(t(sentiCount[,-1]))
# colnames(sentiCount) <- cols
# sentiCount
ggplot(sentiCount) +
  geom_col(aes(x=0, y = Count, fill = sentiment)) +
  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  ggtitle("Queen died Tweets: Positive or Negative") +
  xlab("")
  
```

```{r}
#convert all texts to lowercase and remove punctuations 
rt2 <- tw %>%
  dplyr::select(updated_text) %>%
  unnest_tokens(word, updated_text)

#removing stop words
data("stop_words")
#nrow(rt2)
rt2 = anti_join(rt2,stop_words)

rt4 = rt2 %>%
  inner_join(get_sentiments("loughran")) %>%
  count(word, sentiment, sort = T) %>%
  ungroup()
(sentiCount2 <- rt4 %>% group_by(sentiment) %>% summarise(Count = n()))
sentiCount2 <- sentiCount2 %>% mutate(Count=Count/8.49)

ggplot(sentiCount2) +
  geom_col(aes(x=0, y = Count, fill = sentiment)) +
  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  ggtitle("Queen died Tweets: Positive or Negative (Loughran)") +
  xlab("")
```

